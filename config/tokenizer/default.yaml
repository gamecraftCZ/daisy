_target_: models.tokenizer.Tokenizer

should_train: True
vocab_size: 512
embed_dim: 512
critic_loss_weight: 0
encoder:
  _target_: models.tokenizer.Encoder
  config:
    _target_: models.tokenizer.EncoderDecoderConfig
    resolution: 64
    in_channels: 3
    z_channels: 512
    ch: 64
    ch_mult: [1, 1, 1, 1, 1]
    num_res_blocks: 2
    attn_resolutions: [8, 16]
    out_ch: 3
    dropout: 0.0
decoder:
  _target_: models.tokenizer.Decoder
  config: ${..encoder.config}
tokenizer_critic:
  _target_: models.tokenizer.TokenizerCritic
  config:
    hidden_layer_size: 512
    num_hidden_layers: 2
    input_size: 8192 # ${...encoder.config.z_channels} * 16